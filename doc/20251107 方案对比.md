---
feishu: https://jjspprprpr.feishu.cn/wiki/KjvMwvinuik94PkzxSActonTnFf?fromScene=spaceOverview
feishu_url: "https://feishu.cn/docx/PkkTdO9jho727KxK5tqcJUjgnQh"
feishu_shared_at: "2025-11-27 08:33"
---

## 1 项目背景与目标

### 1.1 背景

当前，我们面临着处理和归类高达亿级规模的招聘信息（Job Descriptions, JD）的挑战。人工分类成本高昂、效率低下且一致性难以保证。为了解决这一问题，我们需要构建一个自动化的智能分类系统，将每一条招聘信息精准地映射到我们预定义的岗位分类体系中。

### 1.2 核心问题

项目的核心挑战在于：**如何在保证高分类准确率的前提下，以最低的资源成本和最高的处理效率，完成对海量（1亿+）存量历史数据和持续增量数据的自动化分类任务**。这要求系统不仅要“算得准”，还要“算得快”和“算得起”。
### 1.3 方案评估


经过初步技术选型分析，对比了三种主流方案，结论如下：

| 方案                       | 优点               | 缺点                               | 综合判断                                            |
| ------------------------ | ---------------- | -------------------------------- | ----------------------------------------------- |
| **1. 开源句向量模型 + 向量相似度匹配** | 性价比极高，技术成熟，部署灵活。 | 准确度依赖调优，需设计校验机制。                 | **当前阶段首选方案**。在成本、效率和精度间取得最佳平衡，适合快速启动和验证。        |
| **2. Bert 微调**           | 端到端微调，可达极高准确率。   | 需大量高质量标注数据，工程链路复杂，成本和周期较长。       | **备选进阶方案**。当方案一无法满足最终精度要求，且预算和人力允许时采用。          |
| **3. LLM 大模型 API**       | 准确度高，理解能力强。      | API调用成本极高，处理亿级数据不具备可行性，网络延迟也是问题。 | **排除方案**。成本过高，不适用于大规模批量处理场景，但可用于辅助生成高质量的测试/验证集。 |
**结论**：本项目将围绕**方案一：开源句向量模型 + 向量相似度匹配**进行详细设计和落地实施。

## 2 方案一：句向量模型
### 2.1 概述

本方案的核心思想是“语义表征与计算分离”。我们不直接训练一个庞大的端到端分类模型，而是利用一个已在大规模通用语料上预训练好的句向量模型（Sentence Embedding Model），将任意文本（无论是JD还是标准岗位描述）映射到一个高维（例如768或1024维）的数学向量空间中。

这个向量可以被视为文本浓缩后的“语义指纹”。一旦所有文本都被向量化，分类任务就转化为在向量空间中进行高效的相似度搜索。这种方式的巨大优势在于：

1. **计算解耦**：将最耗时的“理解”过程（文本到向量的转换）与极速的“匹配”过程（向量相似度计算）分开。亿级数据的向量化是一次性的批量任务，而后续的分类查询则非常迅速。
2. **灵活性与可扩展性**：当需要新增、修改或删除岗位类别时，只需更新标准岗位库及其向量即可，无需重新训练模型，系统维护成本极低。

主要挑战在于，简单的向量相似度计算（如余弦相似度）并不能完全等同于业务逻辑上的“正确分类”。因此，我们必须设计一套包含**置信度分析、多级匹配策略和错误校验**的机制来确保最终的分类质量。

### 2.2 向量模型选择 

**`bge-large-zh-v1.5`** : 由智源研究院（BAAI）推出的 **BGE (Beijing Academy of Artificial Intelligence General Embedding)** 系列模型，专门为中文优化。它在多个中文语义表征评测基准（如 C-MTEB）上长期处于领先地位，被公认为当前最强大的开源中文句向量模型之一。对于理解“后端开发”、“产品经理”、“新媒体运营”这类中文术语的细微差别，它的效果会比通用多语言模型更好。

[quentinz/bge-large-zh-v1.5](https://ollama.com/quentinz/bge-large-zh-v1.5)


向量数据库选择:  ChromaDB

### 2.3 分类表Excel向量化

Excel 数据还是不够直观,需要解析出来, 笛卡尔积组合一下 , 需要是一个完整的句子, 方便后续对比;

将这些向量，连同它们对应的分类ID或分类名称，一起存入本地的 ChromaDB 数据库中

### 2.4 一亿数据准备与向量化

这是整个流程中计算量最大的一步，但这是一次性的。

#### 2.4.1 对比数据集建立

使用 LLM 处理 1000 个数据作为 “正确答案”;

作为后续优化量化准确性的数据集

#### 2.4.2 描述优化

 对于读入的每一条招聘信息，进行与第一阶段类似的文本优化。将其关键信息整合成一个结构化的描述句。

#### 2.4.3 向量化

将一批（例如10000条）优化后的招聘描述文本，发送给本地的 nomic-embed-text 模型，获取它们对应的向量。

### 2.5 相似度计算

将招聘信息向量去`job_categories` 集合（数据库）中进行搜索

#### 2.5.1 置信度分析

1. **高置信度匹配**: 如果 Top 1 的分数**远高于**Top 2（例如，Top 1 分数 0.92，Top 2 分数 0.75），这说明匹配结果非常明确，几乎没有歧义。我们可以直接采纳这个分类结果。
2. **中置信度匹配 / 模糊匹配**: 如果 Top 1, Top 2, 甚至 Top 3 的分数**非常接近**（例如，0.85, 0.83, 0.81），这说明这条招聘信息本身具有语义模糊性，可能同时与“市场助理”、“运营助理”和“销售助理”都有关系。
3. **低置信度匹配**: 如果 Top 1 的分数本身就**很低**（例如，低于 0.6），这说明在您现有的分类体系里，可能根本没有一个合适的分类能描述这条招聘信息。它可能是一个全新的职位，或者描述得非常奇怪。
#### 2.5.2 如何避免出现明显的错误分类

主要是反向验证


## 3 方案二 : Bert 微调方案

因为现在没有测试数据集, 所以最实惠的方案是, 使用LLM为至少1万-5万条数据打上分类标签; (其实成本也不低)

对LLM生成的数据进行抽样，人工检查其准确率。如果准确率很高（例如>95%），可以考虑直接使用。否则，需要投入人力进行修正。


## 4 方案三: LLM 大模型方案

假设每条数据（输入+输出）消耗1000个Token，以每百万Token 1元人民币的优惠价格计算，1亿条数据的总成本将是 1亿 * 1000 / 1,000,000 * 1元 = 10万元。这还是非常保守的估计，实际成本可能更高。