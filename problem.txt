相似度映射重复“余弦→归一化”：我们把集合改成 cosine 度量，同时对向量做 L2 归一化。
    Chroma 在 cosine 模式下返回的 distance 实际上就是 1 - cos_sim。但是查询端又把这个
    distance 当成“单位向量间的 L2 距离”去做 1 - (d²/2) 的逆推，再线性映射到 0~1。等于把
    已经是余弦的得分再次压成接近 1，导致日志里满屏 0.95+，无法区分结果。正确做法是直接用
    cosine_similarity = 1 - distance，甚至不需要额外归一化。
  - 语料域差异仍旧存在：即便得分映射修正，岗位原文仍包含大量公司福利、工作地点、英文片段，
    而库里是“分类术语+任务模板”。向量语境差异会在较难的岗位上放大误匹配概率，这种“部分准
    确、部分不准确”更像语料差距问题，需要在入库前对岗位文本做同构化（提炼职责/任务）或对分
    类语料补充更多真实岗位描述。
  - 日志显示集合里有 2358 条向量，说明导入正常，但 Chroma 仍只看最近邻。部分岗位若在数据库
    里压根没有同类型描述，即便相似度算得高，也只是“最近的坏答案”。需要引入人工校验或阈值自
    适应，而不是固定 0.7。
  - 运行时中断：第一次 go run ./cmd/query 超时被终止，第二次又被外部中断（CLI 显示 aborted
    by user），导致 CSV 只写到 2800 多条。这也会让你看到“不完整的匹配”。

  下一步建议

  1. 把查询端改成 similarity := 1 - distance（在 cosine 模式下），阈值可以重新调到
     0.6~0.7，并记录真实分布。
  2. 给岗位和职业分类统一模板（比如“岗位名称+职责要点+关键技能”），必要时先用小模型抽取摘要
     再送 Embedding。
  3. 为难以分类的岗位添加人工校对/反馈闭环，或者把 Top-N 结果写入 CSV 供人工挑选，提高最终
     准确率。